{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: AIDI 1002 Final Term Project Report\n",
    "\n",
    "Rushda Shaahani Najeeb -200526636@student.gerogianc.on.ca\n",
    "\n",
    "Pranavi Satheesan- 200536120@student.georgianc.on.ca"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "The Heart Attack Analysis & Prediction Dataset is a collection of medical and health-related data that provides insights into various factors that may contribute to the occurrence of a heart attack. The dataset includes information on several patient attributes, such as age, sex, and blood pressure, as well as various other health indicators, such as cholesterol levels, glucose levels, and smoking habits.\n",
    "\n",
    "This dataset is intended to be used for predicting the likelihood of a heart attack occurring in a given patient based on their health indicators and medical history. It contains 13 features and 303 instances, making it a relatively small dataset that is suitable for experimentation with various machine learning algorithms. The dataset is available on Kaggle and is widely used by researchers, data scientists, and machine learning enthusiasts to build predictive models for heart attack analysis and prediction.\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "The Heart Attack Analysis & Prediction Dataset aims to address the problem of heart attacks, which is a leading cause of death worldwide. The dataset provides insights into various factors that may contribute to the occurrence of a heart attack, such as age, sex, blood pressure, cholesterol levels, glucose levels, and smoking habits.\n",
    "\n",
    "The problem that this dataset aims to solve is to predict the likelihood of a heart attack occurring in a given patient based on their health indicators and medical history. This prediction can help healthcare professionals identify patients who are at high risk of having a heart attack and take preventative measures to reduce the risk.\n",
    "\n",
    "Furthermore, the dataset can be used to identify the most important risk factors for heart attacks, which can be helpful in developing targeted prevention strategies. Overall, the Heart Attack Analysis & Prediction Dataset is a valuable resource for researchers and healthcare professionals working to prevent heart attacks and improve patient outcomes.\n",
    "\n",
    "#### Context of the Problem:\n",
    "\n",
    "The problem of predicting the likelihood of a heart attack is important because heart disease is one of the leading causes of death worldwide. According to the World Health Organization, an estimated 17.9 million people died from cardiovascular diseases in 2016, accounting for 31% of all global deaths.\n",
    "\n",
    "Early identification of patients who are at high risk of having a heart attack can lead to early intervention and preventative measures that can save lives. By using the Heart Attack Analysis & Prediction Dataset to develop predictive models, healthcare professionals can identify patients who are at high risk of having a heart attack and take appropriate actions, such as prescribing medication, making lifestyle changes, or referring the patient to a specialist.\n",
    "\n",
    "Moreover, understanding the risk factors for heart attacks can help healthcare professionals develop targeted prevention strategies to reduce the incidence of heart disease. By analyzing the data in the Heart Attack Analysis & Prediction Dataset, researchers can identify the most important risk factors for heart attacks and develop strategies to address them.\n",
    "\n",
    "#### Limitation About other Approaches:\n",
    "\n",
    "Write a sentence or two about limitations of prior appraoches (you will provide their details in the background section next)\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "How the method you are discussing is going to solve it today. Wrtie couple of sentences only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Explain the related work using the following table\n",
    "\n",
    "| Reference |Explanation |  Dataset/Input |Weakness\n",
    "| --- | --- | --- | --- |\n",
    "| Tom et al. [1] | They trained a BERT based transformer to predict answers from the passage of a question| SQUAD dataset for QA | Only 80% accuracy\n",
    "| George et al. [2] | They trained a attention based sequence to sequence model using LSTM to predict answers from the passage of a question| SQUAD V2 dataset for QA | High accuracy but poor on unkown answers\n",
    "\n",
    "\n",
    "The last row in this table should be about the method discussed in this paper (If you can't find the weakenss of this method then write about the future improvement, see the future work section of the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "Provide details of the existing paper method and your contribution that you are implementing in the next section with figure(s).  \n",
    "\n",
    "For figures you can use this tag:\n",
    "\n",
    "![Alternate text ](Figure.png \"Title of the figure, location is simply the directory of the notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "In this section, you will provide the code and its explanation. You may have to create more cells after this. (To keep the Notebook clean, do not display debugging output or thousands of print statements from hundreds of epochs. Make sure it is readable for others by reviewing it yourself carefully.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "heart = pd.read_csv(\"C:/Users/spran/Documents/GitHub/final_project_mlp/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trtbps      0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalachh    0\n",
      "exng        0\n",
      "oldpeak     0\n",
      "slp         0\n",
      "caa         0\n",
      "thall       0\n",
      "output      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check the missing values\n",
    "print(heart.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Direction\n",
    "\n",
    "Write what you have learnt in this project. In particular, write few sentences about the results and their limitations, how they can be extended in future. Make sure your own inference/learnings are depicted here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "[1]:  Authors names, title of the paper, Conference Name,Year, page number (iff available)\n",
    "\n",
    "[2]:  Author names, title of the paper, Journal Name,Journal Vol, Issue Num, Year, page number (iff available)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
